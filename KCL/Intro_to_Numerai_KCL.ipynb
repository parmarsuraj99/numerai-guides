{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to Numerai KCL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeLvSiJmxOurl+YWLlj69/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parmarsuraj99/numerai-guides/blob/master/KCL/Intro_to_Numerai_KCL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBTWq17eht2f"
      },
      "source": [
        "## A code first Introduction to Numerai tournament"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTtkv_-Zjcny"
      },
      "source": [
        "## Overview \n",
        "\n",
        "1. Importing required tools and libraries\n",
        "\n",
        "2. Loading the data\n",
        "3. EDA\n",
        "4. Simple modelling\n",
        "5. Tuning some hyper parameters\n",
        "6. Making and evaluating predictions\n",
        "7. Submittting the predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv4VhgPsl9Md"
      },
      "source": [
        "To speed up the computation, we can use GPU accelaration.\n",
        "\n",
        "`Runtime -> Change runtime type -> Hardware accelarator -> GPU -> save`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9-hCiB_72K9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgVMG-PukRrG"
      },
      "source": [
        "## Importing tools and libraries\n",
        "\n",
        "1. Data loading and EDA:\n",
        "\n",
        "    - numerapi (Numerai's API for downloading latest files)\n",
        "    - Pandas\n",
        "    - numpy\n",
        "    - matplotlib\n",
        "\n",
        "2. Modelling:\n",
        "    \n",
        "    - sklearn\n",
        "    - catboost\n",
        "\n",
        "3. Evaluation\n",
        "\n",
        "    - scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBEVNrLmnAQA"
      },
      "source": [
        "`pip install` is used to install libraries in python environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fdAqhNehtiy"
      },
      "source": [
        "!pip install numerapi\n",
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUJOUYADm19Q"
      },
      "source": [
        "import os   #for OS commands\n",
        "import gc   #garbage collector\n",
        "import csv\n",
        "\n",
        "import numpy as np   #for fast vectorized ops\n",
        "import pandas as pd  #loading .csv file\n",
        "import matplotlib.pyplot as plt #for visualizations\n",
        "\n",
        "import  numerapi     #for programatically loading data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kngzi09Du7yf"
      },
      "source": [
        "napi = numerapi.NumerAPI(verbosity=\"info\")\n",
        "# download current dataset\n",
        "napi.download_current_dataset(unzip=True)\n",
        "\n",
        "current_round = napi.get_current_round()\n",
        "print(f\"Current round: {current_round}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrzbXmiQ7y3_"
      },
      "source": [
        "TOURNAMENT_NAME = \"kazutsugi\"\n",
        "TARGET_NAME = f\"target_{TOURNAMENT_NAME}\"\n",
        "PREDICTION_NAME = f\"prediction_{TOURNAMENT_NAME}\"\n",
        "\n",
        "# Submissions are scored by spearman correlation\n",
        "def correlation(predictions, targets):\n",
        "    ranked_preds = predictions.rank(pct=True, method=\"first\")\n",
        "    return np.corrcoef(ranked_preds, targets)[0, 1]\n",
        "\n",
        "\n",
        "# convenience method for scoring\n",
        "def score(df):\n",
        "    return correlation(df[PREDICTION_NAME], df[TARGET_NAME])\n",
        "\n",
        "\n",
        "# Payout is just the score cliped at +/-25%\n",
        "def payout(scores):\n",
        "    return scores.clip(lower=-0.25, upper=0.25)\n",
        "\n",
        "\n",
        "# Read the csv file into a pandas Dataframe\n",
        "def read_csv(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        column_names = next(csv.reader(f))\n",
        "        dtypes = {x: np.float16 for x in column_names if\n",
        "                  x.startswith(('feature', 'target'))}\n",
        "    return pd.read_csv(file_path, dtype=dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiDS2AG0bh1i"
      },
      "source": [
        "%%time\n",
        "print(\"# Loading data...\")\n",
        "# The training data is used to train your model how to predict the targets.\n",
        "training_data = read_csv(f\"/content/numerai_dataset_{current_round}/numerai_training_data.csv\").set_index(\"id\")\n",
        "# The tournament data is the data that Numerai uses to evaluate your model.\n",
        "tournament_data = read_csv(f\"/content/numerai_dataset_{current_round}/numerai_tournament_data.csv\").set_index(\"id\")\n",
        "\n",
        "example_preds = read_csv(f\"/content/numerai_dataset_{current_round}/example_predictions_target_kazutsugi.csv\")\n",
        "\n",
        "validation_data = tournament_data[tournament_data.data_type == \"validation\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2FtPMmmhkaM"
      },
      "source": [
        "## Scoring Function:\n",
        "\n",
        "Your predictions are scored on their correlation with live targets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KeYE-slcX3t"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5EFdCdG8rF_"
      },
      "source": [
        "training_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szL79jvCcc4O"
      },
      "source": [
        "training_data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f0mGY118q99"
      },
      "source": [
        "feature_names = [feature for feature in training_data.columns if feature.startswith(\"feature\")]\n",
        "print(len(feature_names),\"\\n\",feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnDSdB1Aeb9N"
      },
      "source": [
        "feature_types = [\"intelligence\", \"charisma\", \"strength\", \"dexterity\", \"constitution\", \"wisdom\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHJkU4nUgWWD"
      },
      "source": [
        "### Era"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf2UjCAtfrOx"
      },
      "source": [
        "training_data[\"erano\"] = training_data.era.str.slice(3).astype(int)\n",
        "eras = training_data.erano\n",
        "\n",
        "print(np.unique(training_data['era']), \"\\n Total Eras in training data\", len(np.unique(training_data['era'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PJz9czke11S"
      },
      "source": [
        "training_data.groupby(eras).size().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2YQ3UO5i432"
      },
      "source": [
        "training_data.groupby(TARGET_NAME).size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1LZe43yhJDj"
      },
      "source": [
        "Numerai features are non stationary. i.e, Some feature may be highly correlated in some eras while they may even hurt in another era."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eda1q4PZe1xj"
      },
      "source": [
        "era_ = [1, 10, 22, 37, 50, 111]\n",
        "\n",
        "fig = plt.figure(figsize=(20, 12))\n",
        "\n",
        "for i in range(1, len(era_)+1):\n",
        "\n",
        "    feature_corr = training_data[training_data[\"erano\"]==era_[i-1]][feature_names[:20]].corr(method=\"spearman\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 3, i)\n",
        "    ax.set_title(f\"Era: {era_[i-1]}\")\n",
        "    ax.matshow(feature_corr)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAjebemj4E56"
      },
      "source": [
        "It may happen that your overfitted model perform exceptionally well for 2-3 rounds and then burns heavily in the next round.\n",
        "\n",
        "You want your model to perform well across eras in live data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XhudTtrx6kL"
      },
      "source": [
        "## Simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPAC_44whIga"
      },
      "source": [
        "from sklearn import linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_dAEmHaeb4c"
      },
      "source": [
        "%%time\n",
        "lin_reg = linear_model.LinearRegression()\n",
        "lin_reg.fit(training_data[feature_names], training_data[TARGET_NAME])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRohw9A3v2Wn"
      },
      "source": [
        "tr_preds = lin_reg.predict(training_data[feature_names])\n",
        "tour_preds = lin_reg.predict(tournament_data[feature_names])\n",
        "\n",
        "training_data[PREDICTION_NAME] = tr_preds\n",
        "tournament_data[PREDICTION_NAME] = tour_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na2ssiDLVVqY"
      },
      "source": [
        "#FEATURE_EXPOSURE\n",
        "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "corr_list = []\n",
        "for feature in feature_names:\n",
        "    #print(training_data[feature].values.shape, boosted_tr_preds.squeeze(1).shape)\n",
        "    corr_list.append(correlation(validation_data[feature], \n",
        "                               validation_data[PREDICTION_NAME]))\n",
        "corr_series = pd.Series(corr_list, index=feature_names)\n",
        "print(\"Max Feat. exposure: \", corr_series.describe()[\"max\"])\n",
        "\n",
        "top_k_feats = list(corr_series.nlargest(100).index)\n",
        "print(top_k_feats[:10])\n",
        "\n",
        "# Check the per-era correlations on the training set\n",
        "train_correlations = training_data.groupby(\"era\").apply(score)\n",
        "print(f\"\\nOn training the correlation has mean {train_correlations.mean()} and std {train_correlations.std()}\")\n",
        "\n",
        "# Check the per-era correlations on the validation set\n",
        "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "validation_correlations = validation_data.groupby(\"era\").apply(score)\n",
        "print(f\"\\nOn validation the correlation has mean {validation_correlations.mean()} and std {validation_correlations.std()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWKhcn6rKF72"
      },
      "source": [
        "Models with large exposures to individual features tend to perform poorly or inconsistently out of sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITAgDCnF0Giw"
      },
      "source": [
        "## Let's do some pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3nr1EdNtX6D"
      },
      "source": [
        "Applying some transformations to the data to see how it affects the performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxnC6GDo2GKK"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNS8z9aA0GHc"
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UEDw8og0GD_"
      },
      "source": [
        "pca = PCA(n_components=100)\n",
        "\n",
        "pca.fit(training_data[feature_names])\n",
        "\n",
        "pca_train = pca.transform(training_data[feature_names])\n",
        "pca_tour = pca.transform(tournament_data[feature_names])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJDlQ_2823IU"
      },
      "source": [
        "%%time\n",
        "lin_reg = linear_model.LinearRegression()\n",
        "lin_reg.fit(pca_train, training_data[TARGET_NAME])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYU7-XXk3xiz"
      },
      "source": [
        "tr_preds = lin_reg.predict(pca_train)\n",
        "tour_preds = lin_reg.predict(pca_tour)\n",
        "\n",
        "training_data[PREDICTION_NAME] = tr_preds\n",
        "tournament_data[PREDICTION_NAME] = tour_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqZ0Ld1pVdEa"
      },
      "source": [
        "#FEATURE_EXPOSURE\n",
        "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "corr_list = []\n",
        "for feature in feature_names:\n",
        "    #print(training_data[feature].values.shape, boosted_tr_preds.squeeze(1).shape)\n",
        "    corr_list.append(correlation(validation_data[feature], \n",
        "                               validation_data[PREDICTION_NAME]))\n",
        "corr_series = pd.Series(corr_list, index=feature_names)\n",
        "print(\"Feat. exposure: \", corr_series.describe()[\"std\"])\n",
        "print(\"Max Feat. exposure: \", corr_series.describe()[\"max\"])\n",
        "\n",
        "top_k_feats = list(corr_series.nlargest(100).index)\n",
        "print(top_k_feats[:10])\n",
        "\n",
        "\n",
        "# Check the per-era correlations on the training set\n",
        "train_correlations = training_data.groupby(\"era\").apply(score)\n",
        "print(f\"\\nOn training the correlation has mean {train_correlations.mean()} and std {train_correlations.std()}\")\n",
        "print(f\"On training the average per-era payout is {payout(train_correlations).mean()}\")\n",
        "\n",
        "# Check the per-era correlations on the validation set\n",
        "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "validation_correlations = validation_data.groupby(\"era\").apply(score)\n",
        "print(f\"\\nOn validation the correlation has mean {validation_correlations.mean()} and std {validation_correlations.std()}\")\n",
        "print(f\"On validation the average per-era payout is {payout(validation_correlations).mean()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1P5Kawo_3o3"
      },
      "source": [
        "### Using only some features\n",
        "\n",
        "we can also try modelling using only a few features\n",
        "\n",
        "Some options:\n",
        "\n",
        "- Use a combination of feature group(s) (i.e, intelligence, constitution)\n",
        "- Use top-k features correlated to target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyp63aO8AfF4"
      },
      "source": [
        "corr_list = []\n",
        "for feature in feature_names:\n",
        "    corr_list.append(correlation(training_data[feature],\n",
        "                     training_data[TARGET_NAME]))\n",
        "    \n",
        "corr_series = pd.Series(corr_list, index=feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw4CHahDAe-o"
      },
      "source": [
        "#Here, I have set top-k to 100.\n",
        "selected_features = corr_series.nlargest(100).index\n",
        "print(selected_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA7zaojw-FnL"
      },
      "source": [
        "#Exercise: Select top-k features and train a model using them.\n",
        "#use training_data[selected_features] instead of feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuLbWCjf_iSp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3DOqp8gER64"
      },
      "source": [
        "## Optimization\n",
        "\n",
        "Parameter tuning\n",
        "\n",
        "Cross-validate on group of eras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg20HFshKbmv"
      },
      "source": [
        "from sklearn import model_selection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6uCGuxmKbid"
      },
      "source": [
        "CV = model_selection.GroupKFold(n_splits=3)\n",
        "grp = list(CV.split(X = training_data[feature_names], y = training_data[TARGET_NAME],  groups = eras))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qibcRf86EucR"
      },
      "source": [
        "grp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2oAGMyh_zDx"
      },
      "source": [
        "Optimising [Ridge Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) for alpha"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNlOdmImFxZW"
      },
      "source": [
        "R = linear_model.Ridge(copy_X=True, fit_intercept=True, max_iter=None,\n",
        "                       normalize=False, random_state=None, solver='auto') \n",
        "#make sure you omit the keyword arguments for the parameter(s) you wish to optimize\n",
        "\n",
        "params1 = {'alpha': [0.001, 0.01, 0.1]}\n",
        "GS = model_selection.GridSearchCV(estimator = R, param_grid = params1, \n",
        "                                  cv = grp, return_train_score = True)\n",
        "\n",
        "GS.fit(training_data[feature_names].values, training_data[TARGET_NAME].values)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_n7W8TXy7oe"
      },
      "source": [
        "GS.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq-3NKwkDEZ_"
      },
      "source": [
        "Exercise: \n",
        "\n",
        "tune more parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylFNM-v386S2"
      },
      "source": [
        "tr_preds = GS.predict(training_data[feature_names].values)\n",
        "tour_preds = GS.predict(tournament_data[feature_names].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0ucMDE2FtKO"
      },
      "source": [
        "training_data[PREDICTION_NAME] = tr_preds\n",
        "tournament_data[PREDICTION_NAME] = tour_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6roDxTXCMg1"
      },
      "source": [
        "#FEATURE_EXPOSURE\n",
        "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "corr_list = []\n",
        "for feature in feature_names:\n",
        "    #print(training_data[feature].values.shape, boosted_tr_preds.squeeze(1).shape)\n",
        "    corr_list.append(correlation(validation_data[feature], \n",
        "                               validation_data[PREDICTION_NAME]))\n",
        "corr_series = pd.Series(corr_list, index=feature_names)\n",
        "print(\"Feat. exposure: \", corr_series.describe()[\"std\"])\n",
        "print(\"Max Feat. exposure: \", corr_series.describe()[\"max\"])\n",
        "\n",
        "top_k_feats = list(corr_series.nlargest(100).index)\n",
        "print(top_k_feats[:10])\n",
        "\n",
        "\n",
        "# Check the per-era correlations on the training set\n",
        "train_correlations = training_data.groupby(\"era\").apply(score)\n",
        "print(f\"\\nOn training the correlation has mean {train_correlations.mean()} and std {train_correlations.std()}\")\n",
        "\n",
        "# Check the per-era correlations on the validation set\n",
        "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "validation_correlations = validation_data.groupby(\"era\").apply(score)\n",
        "print(f\"\\nOn validation the correlation has mean {validation_correlations.mean()} and std {validation_correlations.std()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3XiCPE5H68W"
      },
      "source": [
        "## Boosting Models\n",
        "\n",
        "- CatBoost (because it comes with GPU support on Colab)\n",
        "- You can try other libraries like XGBoost and LightGBM too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfZM5ijdIPwF"
      },
      "source": [
        "from catboost import CatBoostRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBekvi-0IT7c"
      },
      "source": [
        "#Default parameters\n",
        "params = {\n",
        "    \"iterations\":500,\n",
        "    \"task_type\":\"GPU\"\n",
        "}\n",
        "\n",
        "cat_reg = CatBoostRegressor(**params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oLictM1IPsB"
      },
      "source": [
        "cat_reg.fit(training_data[feature_names].values, training_data[TARGET_NAME].values,\n",
        "            eval_set=(validation_data[feature_names].values, validation_data[TARGET_NAME].values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jJk5lEEIrIO"
      },
      "source": [
        "%%time\n",
        "\n",
        "tr_preds = cat_reg.predict(training_data[feature_names])\n",
        "tour_preds = cat_reg.predict(tournament_data[feature_names])\n",
        "\n",
        "training_data[PREDICTION_NAME] = tr_preds\n",
        "tournament_data[PREDICTION_NAME] = tour_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSqVeNHLvkfP"
      },
      "source": [
        "#FEATURE_EXPOSURE\n",
        "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "corr_list = []\n",
        "for feature in feature_names:\n",
        "    #print(training_data[feature].values.shape, boosted_tr_preds.squeeze(1).shape)\n",
        "    corr_list.append(correlation(validation_data[feature], \n",
        "                               validation_data[PREDICTION_NAME]))\n",
        "corr_series = pd.Series(corr_list, index=feature_names)\n",
        "print(\"Feat. exposure: \", corr_series.describe()[\"std\"])\n",
        "print(\"Max Feat. exposure: \", corr_series.describe()[\"max\"])\n",
        "\n",
        "top_k_feats = list(corr_series.nlargest(100).index)\n",
        "print(top_k_feats[:10])\n",
        "\n",
        "\n",
        "# Check the per-era correlations on the training set\n",
        "train_correlations = training_data.groupby(\"era\").apply(score)\n",
        "print(f\"\\nOn training the correlation has mean {train_correlations.mean()} and std {train_correlations.std()}\")\n",
        "\n",
        "# Check the per-era correlations on the validation set\n",
        "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "validation_correlations = validation_data.groupby(\"era\").apply(score)\n",
        "print(f\"\\nOn validation the correlation has mean {validation_correlations.mean()} and std {validation_correlations.std()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewywgLtLCYtZ"
      },
      "source": [
        "Exercise: Tune catboost parameters\n",
        "\n",
        "https://www.dezyre.com/recipes/find-optimal-parameters-for-catboost-using-gridsearchcv-for-regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnwDlpaFCnSm"
      },
      "source": [
        "Let's see how the example_predictions perform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEkFcrmyCryY"
      },
      "source": [
        "tournament_data[PREDICTION_NAME] = example_preds[\"prediction_kazutsugi\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaNr1adpCsy1"
      },
      "source": [
        "#FEATURE_EXPOSURE\n",
        "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "corr_list = []\n",
        "for feature in feature_names:\n",
        "    #print(training_data[feature].values.shape, boosted_tr_preds.squeeze(1).shape)\n",
        "    corr_list.append(correlation(validation_data[feature], \n",
        "                               validation_data[PREDICTION_NAME]))\n",
        "corr_series = pd.Series(corr_list, index=feature_names)\n",
        "print(\"Feat. exposure: \", corr_series.describe()[\"std\"])\n",
        "print(\"Max Feat. exposure: \", corr_series.describe()[\"max\"])\n",
        "\n",
        "top_k_feats = list(corr_series.nlargest(100).index)\n",
        "print(top_k_feats[:10])\n",
        "\n",
        "# Check the per-era correlations on the validation set\n",
        "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "validation_correlations = validation_data.groupby(\"era\").apply(score)\n",
        "print(f\"\\nOn validation the correlation has mean {validation_correlations.mean()} and std {validation_correlations.std()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6yIvWr2CznF"
      },
      "source": [
        "These are really good scores. You should try to get comparable results to this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1uCRyDuh1LS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgf4AwRHh1E8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi1QmHvK8_y4"
      },
      "source": [
        "## Making Final Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8e4BqrDh7Cl"
      },
      "source": [
        "tournament_data.to_csv(\"sub_model_name_\"+TOURNAMENT_NAME + \"_submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfHOUAhzTYzx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEfqpxcEWDdK"
      },
      "source": [
        "\n",
        "public_id = \"\"\n",
        "secret_key = \"\"\n",
        "model_id = \"\"\n",
        "napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeAIJHaoW3VU"
      },
      "source": [
        "submission_id = napi.upload_predictions(f\"sub_model_name_\"+TOURNAMENT_NAME + \"_submission.csv\", model_id=model_id)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}